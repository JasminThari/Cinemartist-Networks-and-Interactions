{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import regex as re\n",
    "import unicodedata\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx \n",
    "from collections import Counter\n",
    "from fa2 import ForceAtlas2\n",
    "from Functions import DataCleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataCollection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-120b96327cfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         }\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdata_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdata_movie_artist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataCollection' is not defined"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        \"thriller\": {\"years\": [\"2020s\",\"2010s\", \"2000s\"],\n",
    "                \"sub_years\": [[\"2020\", \"2021\", \"2022\"],[\"2010\", \"2011\", \"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\"],[[]]]}, \n",
    "        \"action\": {\"years\": [\"2020s\",\"2010s\", \"2000s\"],\n",
    "                \"sub_years\": [[\"2020\", \"2021\", \"2022\"],[\"2010\", \"2011\", \"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\"],[\"2000\", \"2001\", \"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\"2009\"]]},             \n",
    "        \"comedy\": {\"years\": [\"2020s\",\"2010s\", \"2000s\"],\n",
    "                \"sub_years\": [[\"2020\", \"2021\", \"2022\"],[\"2010\", \"2011\", \"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\"],[\"2000\", \"2001\", \"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\"]]},\n",
    "        \"adventure\": {\"years\": [\"2020s\",\"2010s\", \"2000s\"],\n",
    "                \"sub_years\": [[\"2020\", \"2021\", \"2022\", \"2023\"], [\"2010\", \"2011\", \"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\"], [\"2000\", \"2001\", \"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\"2009\"]]}, \n",
    "        \"horror\": {\"years\": [\"2020\", \"2021\", \"2022\", \"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\", \"2000\", \"2001\", \"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\"2009\"], \n",
    "                \"sub_years\": [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]},\n",
    "        \"fantasy\": {\"years\": [\"2020s\",\"2010s\", \"2000s\"],\n",
    "                \"sub_years\": [[[]],[[]],[[]]]}, \n",
    "        \"science_fiction\": {\"years\": [\"2020s\", \"2010s\", \"2000s\"],\n",
    "                \"sub_years\": [[[]],[[]],[[]]]}, \n",
    "        }\n",
    "\n",
    "data_collection = DataCollection()\n",
    "data_movie_artist = pd.DataFrame()\n",
    "for genre in params.keys():\n",
    "    for years, sub_years in zip(params[genre][\"years\"],params[genre][\"sub_years\"]):\n",
    "        data = data_collection.collect_movies_artist_data(genre, years, sub_years)\n",
    "        data_movie_artist = pd.concat([data_movie_artist, data]) \n",
    "\n",
    "data_movie_artist = data_movie_artist.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7456, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movie_artist = pd.read_json('data_movie_artist.json', orient='table')\n",
    "data_movie_artist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaner = DataCleaning(data_movie_artist)\n",
    "data_cleaner.data_cleaning()\n",
    "data_movie_artist_cleaned = data_cleaner.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5780, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movie_artist_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "united states                   3372\n",
       "Mix                              581\n",
       "japan                            211\n",
       "united kingdom                   192\n",
       "europe                           149\n",
       "france                           146\n",
       "south korea                      114\n",
       "china                            110\n",
       "asia                             101\n",
       "india                            100\n",
       "canada                            99\n",
       "hong kong                         89\n",
       "philippines                       86\n",
       "united kingdom united states      84\n",
       "china hong kong                   62\n",
       "australia                         59\n",
       "spain                             58\n",
       "germany                           53\n",
       "canada united states              43\n",
       "russia                            40\n",
       "south america                     21\n",
       "north nmerica                     10\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movie_artist_cleaned['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Country</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hyperref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Director, Cast, Country, Genre, Year, Hyperref]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movie_artist_cleaned[data_movie_artist_cleaned.duplicated(subset=['Title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Country</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hyperref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>The Rhythm Section</td>\n",
       "      <td>reed morano</td>\n",
       "      <td>blake lively,jude law,sterling k brown</td>\n",
       "      <td>united states</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>2020</td>\n",
       "      <td>The_Rhythm_Section</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Title     Director                                    Cast  \\\n",
       "5907  The Rhythm Section  reed morano  blake lively,jude law,sterling k brown   \n",
       "\n",
       "            Country     Genre  Year            Hyperref  \n",
       "5907  united states  Thriller  2020  The_Rhythm_Section  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movie_artist_cleaned[data_movie_artist_cleaned['Title']=='The Rhythm Section']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movie_artist_cleaned['Title'].to_csv('titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_title_column(self, text):\n",
    "    # Remove text within square brackets and parentheses\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "\n",
    "    # Replace \n",
    "    text = text.replace('!', '')\n",
    "    text = text.replace('.', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def clean_text_cast_column(self, text):\n",
    "    # Remove text within square brackets and parentheses\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "\n",
    "    # Replace \n",
    "    text = text.replace('|', '')\n",
    "    text = text.replace('’', \"'\")\n",
    "    text = text.replace('.', '')\n",
    "\n",
    "    # Remove text within double and single quotes\n",
    "    text = re.sub(r\"\\\".*?\\\"\", '', text)\n",
    "    text = re.sub(r\"'.*?'\", '', text)    \n",
    "    return text\n",
    "\n",
    "def clean_text(self, column, lower=True):\n",
    "    self.data[column] = self.data[column].str.replace(r'([a-z])([A-Z])', self.add_whitespace, regex=True) # adds space between concatenated words\n",
    "    self.data[column] = self.data[column].apply(self.change_special_letters) # replace speciel letters with normal letters\n",
    "    self.data[column] = self.data[column].str.strip()\n",
    "    self.data[column] = self.data[column].str.replace(r'\\s+', ' ', regex=True) # removes duplicated whitespaces\n",
    "    if lower: \n",
    "        self.data[column] = self.data[column].str.lower() # lowercase for all besides \n",
    "\n",
    "\n",
    "def clean_conditions(self):\n",
    "    conditions = (\n",
    "        (self.data['Cast'] != '') &\n",
    "        (self.data['Title'] != '') &\n",
    "        (self.data['Cast'] != 'Canada') & \n",
    "        (self.data['Title'] != 'citation needed') &\n",
    "        (self.data['Title'] != 'Kevin VanHook') &\n",
    "        (self.data['Title'] != 'J.T. Petty') &\n",
    "        (self.data['Title'] != 'Reggie Bannister michael hoffman jr')\n",
    "    )\n",
    "    self.data = self.data[conditions].reset_index(drop=True)\n",
    "\n",
    "    # These titles with the corresponding director is wrong entries. \n",
    "    incorrect_entries = [\n",
    "        ('Hot Tub Time Machine', 'sean anders john morris'),\n",
    "        ('The Matrix Reloaded', 'the wachowskis nb 9'),\n",
    "        ('The Matrix Revolutions', 'the wachowskis nb 10'),\n",
    "        ('Jade Warrior', 'tommi eronen'),\n",
    "        ('The Bleeding', 'charles picerni'),\n",
    "        ('The Huntsman: Winter\\'s War', 'frank darabont'),\n",
    "        ('Stowaway', 'adam lipsius'), \n",
    "        ('World War Z', 'chris la martina')]\n",
    "    \n",
    "    for title, wrong_director in incorrect_entries:\n",
    "        idx_to_remove = self.data[(self.data['Title'] == title) & \n",
    "                                    (self.data['Director'].str.lower() == wrong_director.lower())].index\n",
    "        self.data = self.data.drop(idx_to_remove)\n",
    "\n",
    "    # Define movies to remove due to wrong year\n",
    "    movies_to_remove_year = {\n",
    "                    'Run Sweetheart Run': \"2022\",\n",
    "                    'The Black Phone': \"2022\",\n",
    "                    'Bhool Bhulaiyaa 2': \"2021\",\n",
    "                    'Apartment 143': \"2012\",\n",
    "                    'Underworld: Blood Wars': \"2017\", \n",
    "                    'Bloody Bloody Bible Camp': '2012', \n",
    "                    'Flash Point': '2006', \n",
    "                    'Kingsman: The Secret Service': '2015', \n",
    "                    'Battle Royale': '2001',\n",
    "                    'Smokin\\' Aces': '2007',\n",
    "                    'Tokyo Gore Police': '2007',\n",
    "                    'Sky Captain and the World of Tomorrow': '2003',\n",
    "                    'Decoys': '2003', \n",
    "                    'How to Talk to Girls at Parties': '2018',\n",
    "                    'Monsters: Dark Continent': '2014', \n",
    "                    'Kingsman: The Secret Service': '2015', \n",
    "                    'Donkey Punch': '2007', \n",
    "                    'Manborg': '2010', \n",
    "                    'Army of Frankensteins': '2014',\n",
    "                    'Growth':'2009', \n",
    "                    'Universal Soldier: Regeneration': '2010',\n",
    "                    'Army of Frankensteins': '2014',\n",
    "                    'BloodRayne': '2006',\n",
    "                    '300': '2007', \n",
    "                    'M3GAN': '2023', \n",
    "                    'Excision': '2008', \n",
    "                    'Color Out of Space': '2020',\n",
    "                    'Faust: Love of the Damned': '2001',\n",
    "                    'Bunshinsaba': '2012',\n",
    "                    'An American Haunting': '2006',\n",
    "                    'The Gingerdead Man': '2006', \n",
    "                    'Big Bad Wolf': '2007',\n",
    "                    'Hurt': '2008',\n",
    "                    'Strigoi': '2009',\n",
    "                    'Seventh Son': '2015', \n",
    "                    'The Shape of Water': '2018', \n",
    "                    'Beowulf & Grendel': '2006', \n",
    "                    'Dirty Deeds': '2002', \n",
    "                    'Beowulf Grendel': '2006'}\n",
    "    \n",
    "    movies_to_remove_hyperref = {'The Beach': 'The_Beach_(2000_film)', \n",
    "                                    'Edge of Tomorrow': 'Edge_of_Tomorrow_(film)', \n",
    "                                    'The Medallion': 'The_Medallion_(film)'}\n",
    "        \n",
    "    # Create a mask for all movies to be removed at once\n",
    "    mask_year = self.data.apply(lambda x: (x['Title'], x['Year']) in movies_to_remove_year.items(), axis=1)\n",
    "    self.data = self.data[~mask_year].reset_index(drop=True)\n",
    "\n",
    "    mask_hyperref = self.data.apply(lambda x: (x['Title'], x['Hyperref']) in movies_to_remove_hyperref.items(), axis=1)\n",
    "    self.data = self.data[~mask_hyperref].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_director_column(self, text):\n",
    "    # Remove text within square brackets and parentheses\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'\\(.*?\\)', '', text)\n",
    "\n",
    "    # Replace + and & with a comma\n",
    "    text = text.replace('+', ',')\n",
    "    text = text.replace('&', ',')\n",
    "    text = text.replace('-', ' ')\n",
    "    text = text.replace('—', ' ')\n",
    "    text = text.replace('.', '')\n",
    "\n",
    "    # Remove text within double and single quotes\n",
    "    text = re.sub(r\"\\\".*?\\\"\", '', text)\n",
    "    text = re.sub(r\"'.*?'\", '', text)    \n",
    "    return text\n",
    "\n",
    "def consolidate_directors(self):\n",
    "    def inner_consolidate_directors(group):\n",
    "            # Find the longest director name\n",
    "        longest_director = max(group, key=len)\n",
    "        # Split the longest name into a set of words for easy comparison\n",
    "        longest_director_words = set(longest_director.lower().split())\n",
    "\n",
    "        # Function to check if any part of a shorter name is in the longest name\n",
    "        def is_subname_any(shorter, longer_words):\n",
    "            shorter_words = set(shorter.lower().split())\n",
    "            # Check if any word from the shorter name is in the longer name\n",
    "            return any(word in longer_words for word in shorter_words)\n",
    "\n",
    "        # Consolidate director names\n",
    "        group = [longest_director if is_subname_any(d, longest_director_words) else d for d in group]\n",
    "        return group\n",
    "    self.data['Director'] = self.data.groupby('Title')['Director'].transform(inner_consolidate_directors)\n",
    "\n",
    "def data_clean_director(self):\n",
    "    self.data.apply(clean_text_director_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def differentiate_same_title(self):\n",
    "    different_directors = self.data[self.data.duplicated(subset=['Title'], keep=False) &\n",
    "                                    self.data.groupby(['Title'])['Director'].transform('nunique').ne(1)]\n",
    "    for index, row in different_directors.iterrows():\n",
    "        self.data.loc[index, 'Title'] = row['Title'] + ' ' + row['Director']\n",
    "    self.data = self.data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clean_genres(self):\n",
    "    # Define your specific genre combinations and their new names\n",
    "    genre_combinations = {\n",
    "                        ('horror',): 'Horror',\n",
    "                        ('comedy',): 'Comedy',\n",
    "                        ('action',): 'Action',\n",
    "                        ('thriller',): 'Thriller',\n",
    "                        ('science_fiction',): 'Science Fiction',\n",
    "                        ('adventure',): 'Adventure',\n",
    "                        ('fantasy',): 'Fantasy',\n",
    "                        ('action', 'science_fiction'): 'Science Fiction',\n",
    "                        ('action', 'thriller'): 'Action',\n",
    "                        ('action', 'comedy'): 'Action',\n",
    "                        ('adventure', 'fantasy'): 'Fantasy',\n",
    "                        ('comedy', 'horror'): 'Horror',\n",
    "                        ('comedy', 'fantasy'): 'Fantasy',\n",
    "                        ('horror', 'science_fiction'): 'Science Fiction',\n",
    "                        ('horror', 'thriller'): 'Horror',\n",
    "                        ('adventure', 'science_fiction'): 'Science Fiction',\n",
    "                        ('action', 'adventure'): 'Action',\n",
    "                        ('action', 'adventure', 'science_fiction'): 'Science Fiction',\n",
    "                        ('adventure', 'comedy'): 'Comedy'}\n",
    "\n",
    "    # Group by title and apply a set to the 'Genre' column\n",
    "    title_genres = self.data.groupby('Title')['Genre'].apply(set).reset_index()\n",
    "\n",
    "    # Convert the set of genres to a sorted tuple\n",
    "    title_genres['genre_combination'] = title_genres['Genre'].apply(lambda x: tuple(sorted(x)))\n",
    "\n",
    "    # Map the genre combinations to the desired string or 'other'\n",
    "    title_genres['Genre'] = title_genres['genre_combination'].apply(\n",
    "        lambda genre_tuple: genre_combinations.get(genre_tuple, 'Mix'))\n",
    "\n",
    "    # Map titles to their new genre\n",
    "    title_to_new_genre = pd.Series(title_genres['Genre'].values, index=title_genres['Title']).to_dict()\n",
    "    self.data['Genre'] = self.data['Title'].map(title_to_new_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_country_column(self, text):\n",
    "    # Remove text within square brackets and parentheses\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # Replace \n",
    "    text = text.replace('-', ',')\n",
    "    text = text.replace('<', \"\")\n",
    "    text = text.replace('.', '')\n",
    "    text = text.replace('\\{', '')\n",
    "    return text\n",
    "\n",
    "def unique_country_combinations(data):\n",
    "    unique_combinations = {}\n",
    "    unique_country_combinations = []\n",
    "    for index, row in data.iterrows():\n",
    "        country_combination = ' '.join(sorted(row['Country'].split()))\n",
    "        if country_combination not in unique_combinations:\n",
    "            unique_combinations[country_combination] = row['Country']\n",
    "            unique_country_combinations.append(country_combination)\n",
    "        else:\n",
    "            first_occurrence_index = unique_country_combinations.index(country_combination)\n",
    "            unique_country_combinations.append(unique_country_combinations[first_occurrence_index])\n",
    "    data['Country'] = [unique_combinations[combination] for combination in unique_country_combinations]\n",
    "    return data\n",
    "\n",
    "def map_country_to_continent(self):\n",
    "    country_counts = self.data['Country'].value_counts()\n",
    "    continent_mapping = {\n",
    "        'North America': ['united states', 'canada', 'mexico', 'honduras'],\n",
    "        'United States': ['usa', 'american'],\n",
    "        'Asia': ['indonesia', 'japan', 'taiwan', 'hong kong', 'china', 'south korea', 'myanmar', 'india', 'israel', 'jordan', 'qatar', 'japan', 'thailand', 'singapore', \n",
    "                'malaysia', 'kazakhstan', 'vietnam', 'pakistan', 'philippines', 'bangladesh', 'bhutan', 'cambodia', 'laos', 'brunei', 'timor-leste', 'mongolia', \n",
    "                'tajikistan', 'kyrgyzstan', 'turkmenistan', 'uzbekistan', 'kazakhstan', 'nepal'],\n",
    "        'Europe': ['italy', 'germany', 'france', 'norway', 'sweden', 'ireland', 'new zealand', 'netherlands', 'denmark', 'united kingdom', 'spain', 'belgium', 'poland', \n",
    "                'czech republic', 'russia', 'austria', 'switzerland', 'iceland', 'greece', 'romania', 'serbia', 'turkey', 'luxembourg', 'portugal', 'malta', \n",
    "                'bulgaria', 'ireland', 'croatia', 'slovenia', 'slovakia', 'latvia', 'estonia', 'hungary', 'belarus', 'lithuania', 'macedonia', 'monaco', \n",
    "                    'armenia', 'kazakhstan', 'poland', 'estonia', 'hungary', 'lithuania', 'slovenia', 'slovakia', 'estonia'],\n",
    "        'South America': ['argentina', 'chile', 'peru', 'brazil', 'colombia', 'ecuador', 'french guiana', 'trinidad and tobago', 'venezuela', 'guyana', 'suriname']}\n",
    "\n",
    "    def inner_map_country_to_continent(country):\n",
    "        if country_counts.get(country, 0) < 45:\n",
    "            for continent, countries in continent_mapping.items():\n",
    "                if country in countries:\n",
    "                    return continent\n",
    "            return \"Mix\"\n",
    "        return country\n",
    "    self.data['Country'] = self.data['Country'].apply(inner_map_country_to_continent)\n",
    "    \n",
    "\n",
    "def clean_country(self): \n",
    "    # Identifying rows with the longest 'Country' for each 'Title'\n",
    "    different_country = self.data[self.data.duplicated(subset=['Title'], keep=False) & \n",
    "                                    self.data.groupby(['Title'])['Country'].transform('nunique').ne(1)]\n",
    "    \n",
    "    # Remove rows with 'other' country, except those identified above\n",
    "    only_other_country = self.data.groupby('Title').filter(lambda x: (x['Country'] == 'other').all())\n",
    "    different_country = different_country[~((different_country['Country'] == 'other') & \n",
    "                                            ~different_country['Title'].isin(only_other_country['Title']))]\n",
    "    \n",
    "    # Identify the row with the longest country name for each title\n",
    "    max_length_indices = different_country.groupby('Title')['Country'].apply(lambda x: x.str.len().idxmax())\n",
    "    rows_to_keep = different_country.loc[max_length_indices]\n",
    "\n",
    "    # First, remove all rows with the titles that have duplicates in different_country\n",
    "    self.data = self.data[~self.data['Title'].isin(different_country['Title'])]\n",
    "    \n",
    "    # Then, append the rows to keep to the filtered DataFrame\n",
    "    self.data = self.data.append(rows_to_keep).reset_index(drop=True)\n",
    "\n",
    "def data_clean_country(self):\n",
    "    self.data = self.data.apply(self.clean_text_country_column)\n",
    "    self.clean_text('Country')\n",
    "    self.unique_country_combinations()\n",
    "    self.map_country_to_continent()\n",
    "    self.clean_country()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(self): \n",
    "    self.data = self.data.drop_duplicates(keep='first')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
